{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172bd9e0",
   "metadata": {},
   "source": [
    "### Technical Demonstration ACID operations - Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405213ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/12 15:02:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Import SparkSession (main entry point to Spark) and PySpark SQL functions\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "#from delta import configure_spark_with_delta_pip # (optional: only needed if you use pip-based Delta setup)\n",
    "\n",
    "# Create or get an existing SparkSession\n",
    "# This is how we initialize Spark in Python so we can read/write data, run SQL queries, etc.\n",
    "spark = (SparkSession.builder\n",
    "         # Give the Spark application a name\n",
    "         .appName(\"ACID\")\n",
    "         # Enable Delta Lake support in this Spark session.\n",
    "         # This tells Spark to load Delta’s SQL extensions (ACID, MERGE, UPDATE, DELETE, etc.)\n",
    "         .config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "         # Replace Spark’s default catalog with Delta’s catalog,\n",
    "         # so operations like spark.read.table(), CREATE TABLE, etc. understand Delta tables.\n",
    "         .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "         # Build and return the SparkSession object.\n",
    "         # If a session already exists, Spark reuses it.\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac355ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[fixed acidity: double, volatile acidity: double, citric acid: double, residual sugar: double, chlorides: double, free sulfur dioxide: double, total sulfur dioxide: double, density: double, pH: double, sulphates: double, alcohol: double, quality: int]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a structured dataset (the wine-quality CSV) into a Spark DataFrame,\n",
    "df = spark.read.csv(\"/CA1/ACID/winequality-red.csv\", header = True, inferSchema = True, sep = \";\")\n",
    "# Bring data to memory, cache the data\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8417605f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is an action in spark, creates a spark job and count \n",
    "# all the rows using parallel processing (it is controlled by Spark) across the cpu cores in the local machine\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e78a750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fixed acidity: double, volatile acidity: double, citric acid: double, residual sugar: double, chlorides: double, free sulfur dioxide: double, total sulfur dioxide: double, density: double, pH: double, sulphates: double, alcohol: double, quality: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the dataFrame schema (columns + types)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02536b6e",
   "metadata": {},
   "source": [
    "###### Check for Nulls in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65f3ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      null_count\n",
       "fixed acidity                  0\n",
       "volatile acidity               0\n",
       "citric acid                    0\n",
       "residual sugar                 0\n",
       "chlorides                      0\n",
       "free sulfur dioxide            0\n",
       "total sulfur dioxide           0\n",
       "density                        0\n",
       "pH                             0\n",
       "sulphates                      0\n",
       "alcohol                        0\n",
       "quality                        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for null values\n",
    "# For each column c, create a new column named c that contains the number of null values in that column.\n",
    "df_result = df.select([\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "# Convert to pandas for a better visualisation\n",
    "df_result_pd = df_result.toPandas().T  # Transpose for vertical display\n",
    "df_result_pd.columns = [\"null_count\"] # Add column name null count\n",
    "display(df_result_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1da91",
   "metadata": {},
   "source": [
    "###### Check for Duplicate rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a58691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1599\n",
      "Unique rows: 1359\n",
      "Duplicate rows: 240\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates rows\n",
    "total_rows = df.count()\n",
    "unique_rows = df.dropDuplicates().count()\n",
    "duplicates = total_rows - unique_rows\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Unique rows: {unique_rows}\")\n",
    "print(f\"Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf1e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicates\n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a85d3379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1359\n",
      "Unique rows: 1359\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates rows\n",
    "total_rows = df.count() # total number of rows\n",
    "unique_rows = df.dropDuplicates().count() # number of distinct rows, after removing duplicates only one copy of each unique record remains.\n",
    "duplicates = total_rows - unique_rows # duplicates\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Unique rows: {unique_rows}\")\n",
    "print(f\"Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b547a",
   "metadata": {},
   "source": [
    "###### Prepare the dataset for inserting a row and for training neural network models. A copy of an existing row is created and modified (its label changed) and then inserted in the dataset to demonstrate that this lakehouse architecture (Delta Lake) does support ACID transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb5609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column id + column label (quality >= 7 -> good wine)\n",
    "df = (df.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "         .withColumn(\"label\", (F.col(\"quality\") >= 7).cast(\"int\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d93395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fixed acidity: double, volatile acidity: double, citric acid: double, residual sugar: double, chlorides: double, free sulfur dioxide: double, total sulfur dioxide: double, density: double, pH: double, sulphates: double, alcohol: double, quality: int, id: bigint, label: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the new dataFrame schema (columns + types) after adding columns id and label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c509ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+\n",
      "| id|label|quality|\n",
      "+---+-----+-------+\n",
      "|  0|    0|      4|\n",
      "|  1|    0|      5|\n",
      "|  2|    1|      7|\n",
      "|  3|    1|      7|\n",
      "|  4|    0|      6|\n",
      "|  5|    0|      5|\n",
      "|  6|    0|      5|\n",
      "|  7|    1|      7|\n",
      "|  8|    0|      5|\n",
      "|  9|    0|      6|\n",
      "| 10|    0|      6|\n",
      "| 11|    0|      5|\n",
      "| 12|    0|      6|\n",
      "| 13|    0|      6|\n",
      "| 14|    0|      6|\n",
      "| 15|    1|      7|\n",
      "| 16|    0|      6|\n",
      "| 17|    0|      5|\n",
      "| 18|    1|      7|\n",
      "| 19|    1|      8|\n",
      "+---+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select -> This is a transformation, meaning Spark is defining what you want to do \n",
    "# (create a new logical plan), but not executing it yet. In other words, \n",
    "# create a new logical DataFrame that only keeps these three columns: id, label, and quality\n",
    "# show -> this is the action that triggers Spark to actually execute the plan\n",
    "df.select(\"id\", \"label\", \"quality\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c1cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize the dataframe, removing the column quality\n",
    "# Python list comprehension with all the columns removing id, quality and label \n",
    "feature_cols = [c for c in df.columns if c not in (\"id\", \"quality\", \"label\")]\n",
    "# add the id column at the beggining and label at the end\n",
    "df = df.select(\"id\", *feature_cols, \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d2cb014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'label']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a Python list containing the names of all the columns in the spark dataFrame, in order.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f37de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataframe using a seed (always the same order), then select the first element.\n",
    "# then return a list with one element. [0] returns the first row of that list  \n",
    "row = df.orderBy(F.rand(42)).limit(1).collect()[0]\n",
    "# return the id\n",
    "bad_id = row[\"id\"]\n",
    "# return the label for that row\n",
    "orig_label = row[\"label\"]\n",
    "# I change the label\n",
    "fix_label = 1 - orig_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ce1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a condition id == bad_id\n",
    "cond = F.col(\"id\") == bad_id\n",
    "# .withColumn()-> adds or replaces a column, transofrmation\n",
    "# F.lit(fix_label)-> creates a literal constant value for every row\n",
    "# where() -> tells Spark which rows you want, transformation\n",
    "# From DataFrame df, take the rows that satisfy cond,\n",
    "# and assign (or overwrite) their label column with the constant value fix_label\n",
    "row_fix = df.where(cond).withColumn(\"label\", F.lit(fix_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356eed8",
   "metadata": {},
   "source": [
    "###### The following two rows have identical feature values but different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650a115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 255, 'fixed acidity': 8.9, 'volatile acidity': 0.875, 'citric acid': 0.13, 'residual sugar': 3.45, 'chlorides': 0.088, 'free sulfur dioxide': 4.0, 'total sulfur dioxide': 14.0, 'density': 0.9994, 'pH': 3.44, 'sulphates': 0.52, 'alcohol': 11.5, 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Convert that Spark Row object into a Python dictionary\n",
    "print(row.asDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abbe9afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 255, 'fixed acidity': 8.9, 'volatile acidity': 0.875, 'citric acid': 0.13, 'residual sugar': 3.45, 'chlorides': 0.088, 'free sulfur dioxide': 4.0, 'total sulfur dioxide': 14.0, 'density': 0.9994, 'pH': 3.44, 'sulphates': 0.52, 'alcohol': 11.5, 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(row_fix.first().asDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b9f55",
   "metadata": {},
   "source": [
    "###### Delta Lake (CLEAN): MERGE upsert -> support ACID properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62537987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# These are characters that I don’t want to appear in the column names.\n",
    "# replace fixed acidity by fixed_acidity\n",
    "bad_chars = [' ', ',', ';', '{', '}', '(', ')', '\\n', '\\t', '=']\n",
    "\n",
    "def sanitize(name: str) -> str:\n",
    "    out = name.strip() # Remove whitespace at start and end\n",
    "    for ch in bad_chars:\n",
    "        out = out.replace(ch, '_') # Replace every unwanted character (bad_chars) with _\n",
    "    return out.lower() # Convert the name to lowercase and return it.\n",
    "\n",
    "# Create a new dataFrame with those cleaned column names.\n",
    "df = df.toDF(*[sanitize(c) for c in df.columns])\n",
    "\n",
    "# Write in Delta Lake format (transactional Parquet files) and overwrite any file in that location.\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/CA1/ACID/clean/winequality-red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01e03370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeltaTable is a Delta Lake abstraction on top of Parquet data\n",
    "# It gives you access to ACID operations (Delta Lake API)\n",
    "from delta.tables import DeltaTable\n",
    "# Open an existing Delta table from the path, It needs the active SparkSession (spark) \n",
    "# to interact with the metadata and files\n",
    "delta_tbl = DeltaTable.forPath(spark, \"/CA1/ACID/clean/winequality-red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3337e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/12 15:08:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|255|    0|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the delta table object (delta_tbl) into a regular spark dataFrame.\n",
    "# filter by cond, selects id and label, and display it.\n",
    "delta_tbl.toDF().filter(cond).select(\"id\", \"label\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "163333d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 51:===================================>                    (32 + 4) / 50]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "bad_chars = [' ', ',', ';', '{', '}', '(', ')', '\\n', '\\t', '=']\n",
    "def sanitize(name: str) -> str:\n",
    "    out = name.strip()\n",
    "    for ch in bad_chars:\n",
    "        out = out.replace(ch, '_')\n",
    "    return out.lower()\n",
    "\n",
    "# Create a new dataFrame with those cleaned column names. This dataframe has only\n",
    "# one row, the one which has the label changed \n",
    "row_fix_aligned = row_fix.toDF(*[sanitize(c) for c in row_fix.columns])\n",
    "\n",
    "# This operations is called UPSERT, because If it exists, update it. If it doesn’t exist, insert it.\n",
    "# whenMatchedUpdateAll() -> if a match is found, update all the columns\n",
    "# whenNotMatchedInsertAll() -> if a match is not found, insert the entire row\n",
    "# ACID support\n",
    "delta_tbl.alias(\"t\").merge(\n",
    "    row_fix_aligned.alias(\"s\"),\n",
    "    \"t.id = s.id\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0df6b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 72:=============================>                          (26 + 4) / 50]\r",
      "\r",
      "[Stage 72:===========================================>            (39 + 5) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|255|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert the delta table object (delta_tbl) into a regular spark dataFrame.\n",
    "# filter by cond, selects id and label, and display it.\n",
    "delta_tbl.toDF().filter(cond).select(\"id\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "588a04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta CLEAN — single correct row for chosen id:\n",
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|255|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Delta CLEAN — single correct row for chosen id:\")\n",
    "spark.read.format(\"delta\").load(\"/CA1/ACID/clean/winequality-red\").select(\"id\", \"label\").where(F.col(\"id\")==bad_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "938bb146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAN table version 0 (before MERGE):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:============================================>           (40 + 4) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|255|    0|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"CLEAN table version 0 (before MERGE):\")\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\",0).load(\"/CA1/ACID/clean/winequality-red\").select(\"id\", \"label\").where(F.col(\"id\")==bad_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6376b89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 97:==================================================>     (45 + 4) / 50]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/CA1/ACID/clean/winequality-red\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f37a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/CA1/ACID/clean/winequality-red\").count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df384e0d",
   "metadata": {},
   "source": [
    "### Train Keras ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be9bd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas numpy scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32dc07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 15:44:21.766322: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-12 15:44:23.432873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-12 15:44:27.539245: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# import libraries to train ANN\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c9f6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list names the input columns — the variables that the model will use to make predictions\n",
    "feature_cols = [\n",
    "    \"fixed_acidity\", \"volatile_acidity\", \"citric_acid\", \"residual_sugar\",\n",
    "    \"chlorides\", \"free_sulfur_dioxide\", \"total_sulfur_dioxide\",\n",
    "    \"density\", \"ph\", \"sulphates\", \"alcohol\"\n",
    "]\n",
    "\n",
    "# this function takes a spark dataframe, as input and returns \n",
    "# NumPy arrays (X, y) — the standard format expected by TensorFlow\n",
    "def to_numpy(sdf):\n",
    "    # This collects the entire spark dataFrame into memory as a pandas dataFrame, it is an action\n",
    "    # Trigger Spark to execute a job and produce a result.\n",
    "    pdf = sdf.toPandas()\n",
    "    # Select only the columns in the list above, and convert those Pandas columns into a 2D NumPy array\n",
    "    # the data is stored as 32-bit floats (what TensorFlow expects).\n",
    "    X = pdf[feature_cols].to_numpy(dtype=np.float32)\n",
    "    # Select the label column and Converts it to a 1D NumPy array of integers\n",
    "    y = pdf[\"label\"].to_numpy(dtype=np.int64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beccfea",
   "metadata": {},
   "source": [
    "#### Train ANN with the dataframe which has the row with the label changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26a06842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the delta table object (delta_tbl) into a regular spark dataFrame.\n",
    "clean_df = delta_tbl.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9efe10eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|255|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the new version contains the changed label \n",
    "clean_df.select(\"id\", \"label\").where(cond).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56951f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  185|\n",
      "|    0| 1174|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how many 0s and 1s are in the dataset using Spark\n",
    "clean_df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79c0eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to_numpy\n",
    "X, y = to_numpy(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99121da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(1174), np.int64(1): np.int64(185)}\n"
     ]
    }
   ],
   "source": [
    "# Check how many 0s and 1s are in the dataset using numpy\n",
    "unique, counts = np.unique(y, return_counts=True) \n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdd755f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing subsets\n",
    "# test_size= 0.2 -> 20% of the data will go to the test set, and 80% will go to the training set\n",
    "# If you have 1,599 samples: Training set is ~1,279 rows and Test set is 320 rows approximately\n",
    "# Ensure the same split every time you run the code, otherwise different 20% of rows go to X_test each time \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15d47fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.338547</td>\n",
       "      <td>0.530603</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>2.527691</td>\n",
       "      <td>0.088157</td>\n",
       "      <td>16.013340</td>\n",
       "      <td>46.659153</td>\n",
       "      <td>0.996735</td>\n",
       "      <td>3.309908</td>\n",
       "      <td>0.656734</td>\n",
       "      <td>10.439558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.730869</td>\n",
       "      <td>0.185112</td>\n",
       "      <td>0.195892</td>\n",
       "      <td>1.374252</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>10.605497</td>\n",
       "      <td>32.942955</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.153877</td>\n",
       "      <td>0.161211</td>\n",
       "      <td>1.069283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997860</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1087.000000  1087.000000  1087.000000  1087.000000  1087.000000   \n",
       "mean      8.338547     0.530603     0.271739     2.527691     0.088157   \n",
       "std       1.730869     0.185112     0.195892     1.374252     0.049906   \n",
       "min       4.600000     0.120000     0.000000     0.900000     0.012000   \n",
       "25%       7.100000     0.390000     0.090000     1.900000     0.070000   \n",
       "50%       7.900000     0.520000     0.260000     2.200000     0.079000   \n",
       "75%       9.300000     0.642500     0.430000     2.600000     0.091000   \n",
       "max      15.900000     1.580000     1.000000    15.500000     0.611000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1087.000000  1087.000000  1087.000000  1087.000000  1087.000000   \n",
       "mean     16.013340    46.659153     0.996735     3.309908     0.656734   \n",
       "std      10.605497    32.942955     0.001863     0.153877     0.161211   \n",
       "min       1.000000     6.000000     0.990070     2.740000     0.370000   \n",
       "25%       7.000000    22.000000     0.995600     3.210000     0.550000   \n",
       "50%      13.000000    38.000000     0.996700     3.310000     0.620000   \n",
       "75%      22.000000    62.000000     0.997860     3.400000     0.730000   \n",
       "max      72.000000   289.000000     1.003690     4.010000     2.000000   \n",
       "\n",
       "                10  \n",
       "count  1087.000000  \n",
       "mean     10.439558  \n",
       "std       1.069283  \n",
       "min       8.400000  \n",
       "25%       9.500000  \n",
       "50%      10.200000  \n",
       "75%      11.100000  \n",
       "max      14.900000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap the NumPy array X_train inside a pandas dataFrame to call describe\n",
    "# we check values min and max to verify if they have different scales\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fe81637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 11) (272, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ad24599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize because different features have different scales, and we want them all to \n",
    "# have equal importance for the model\n",
    "# fit on the training set, use the same mean and std from training data to scale the test set\n",
    "# it means that both datasets are on the same scale\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train, X_test = sc.transform(X_train), sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665d42b",
   "metadata": {},
   "source": [
    "###### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fea1b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries from tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "\n",
    "\n",
    "# build a model with two hidden layers\n",
    "# Dense -> fully connected layer (each neuron connects to every neuron in the next layer)\n",
    "# d is the number of input features\n",
    "# activation function relu for both hidden layers\n",
    "# The output layer has one neuron because it is a binary classification (good wine vs bad wine)\n",
    "# The activation function is sigmoid, so the network outputs is a probability: \n",
    "# close to 0 -> class 0 (bad wine)\n",
    "# close to 1 -> class 1 (good wine)\n",
    "# optimizer adam -> to adjusts learning rates during training\n",
    "# loss binary_crossentropy -> used for binary classification\n",
    "# metric accuracy -> to measure performance\n",
    "def build_model(d):\n",
    "    model = Sequential()\n",
    "    # Input + Hidden Layer 1\n",
    "    model.add(Dense(64, input_dim=d, activation=\"relu\"))\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    \n",
    "    # Output Layer    \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "    #model = Sequential()\n",
    "    #model.add(Dense(64, input_dim=d))\n",
    "    #model.add(LeakyReLU(alpha=0.01))   # add activation as a layer\n",
    "    #model.add(Dense(32))\n",
    "    #model.add(LeakyReLU(alpha=0.01))\n",
    "    #model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    #model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbdba8",
   "metadata": {},
   "source": [
    "###### Second Model (includes techniques to improve training and generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7c2530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# build a model with two hidden layers\n",
    "# Dense -> fully connected layer (each neuron connects to every neuron in the next layer)\n",
    "# d is the number of input features\n",
    "# activation function relu for both hidden layers\n",
    "# The output layer has one neuron because it is a binary classification (good wine vs bad wine)\n",
    "# The activation function is sigmoid, so the network outputs is a probability: \n",
    "# close to 0 -> class 0 (bad wine)\n",
    "# close to 1 -> class 1 (good wine)\n",
    "# optimizer adam -> to adjusts learning rates during training\n",
    "# loss binary_crossentropy -> used for binary classification\n",
    "# metric accuracy -> to measure performance\n",
    "# Three core techniques were added to make neural networks train better and \n",
    "# generalize well (Dropout, BatchNormalization and L2)\n",
    "# EarlyStopping and ReduceLROnPlateau are callbacks that help your model train smarter \n",
    "# and avoid overfitting or wasting epochs\n",
    "def build_model1(d):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Input + Hidden Layer 1\n",
    "    model.add(Dense(64, input_dim=d, activation=\"relu\", kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    model.add(Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "    #model = Sequential()\n",
    "    \n",
    "    # Input + Hidden Layer 1\n",
    "    #model.add(Dense(64, input_dim=d, kernel_regularizer=l2(0.001)))\n",
    "    #model.add(LeakyReLU(alpha=0.01))         # Replaces ReLU\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.3))\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    #model.add(Dense(32, kernel_regularizer=l2(0.001)))\n",
    "    #model.add(LeakyReLU(alpha=0.01))         # Replaces ReLU\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.3))\n",
    "    \n",
    "    # Output Layer\n",
    "    #model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile\n",
    "    #model.compile(\n",
    "    #    optimizer=\"adam\",\n",
    "    #    loss=\"binary_crossentropy\",\n",
    "    #    metrics=[\"accuracy\"]\n",
    "    #)\n",
    "    #return model\n",
    "    \n",
    "    \n",
    "es  = EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359178a",
   "metadata": {},
   "source": [
    "###### Training with the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d52c300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/venvs/spark-delta/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-10-11 14:50:56.523711: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 - 1s - 17ms/step - accuracy: 0.8537 - loss: 0.4307 - val_accuracy: 0.8603 - val_loss: 0.3560\n",
      "Epoch 2/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.8675 - loss: 0.3039 - val_accuracy: 0.8824 - val_loss: 0.3097\n",
      "Epoch 3/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8767 - loss: 0.2789 - val_accuracy: 0.8934 - val_loss: 0.2918\n",
      "Epoch 4/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8841 - loss: 0.2699 - val_accuracy: 0.8971 - val_loss: 0.2915\n",
      "Epoch 5/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8813 - loss: 0.2619 - val_accuracy: 0.8934 - val_loss: 0.2753\n",
      "Epoch 6/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8868 - loss: 0.2574 - val_accuracy: 0.9007 - val_loss: 0.2786\n",
      "Epoch 7/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8832 - loss: 0.2566 - val_accuracy: 0.9044 - val_loss: 0.2750\n",
      "Epoch 8/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8924 - loss: 0.2502 - val_accuracy: 0.9081 - val_loss: 0.2803\n",
      "Epoch 9/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.8905 - loss: 0.2473 - val_accuracy: 0.9044 - val_loss: 0.2824\n",
      "Epoch 10/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.8914 - loss: 0.2432 - val_accuracy: 0.9118 - val_loss: 0.2762\n",
      "Epoch 11/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8914 - loss: 0.2409 - val_accuracy: 0.9081 - val_loss: 0.2750\n",
      "Epoch 12/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8997 - loss: 0.2393 - val_accuracy: 0.9081 - val_loss: 0.2760\n",
      "Epoch 13/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.8933 - loss: 0.2359 - val_accuracy: 0.9118 - val_loss: 0.2764\n",
      "Epoch 14/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8997 - loss: 0.2333 - val_accuracy: 0.9118 - val_loss: 0.2798\n",
      "Epoch 15/200\n",
      "68/68 - 1s - 7ms/step - accuracy: 0.8970 - loss: 0.2313 - val_accuracy: 0.9081 - val_loss: 0.2820\n",
      "Epoch 16/200\n",
      "68/68 - 1s - 8ms/step - accuracy: 0.8960 - loss: 0.2283 - val_accuracy: 0.9081 - val_loss: 0.2768\n",
      "Epoch 17/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9006 - loss: 0.2263 - val_accuracy: 0.9081 - val_loss: 0.2802\n",
      "Epoch 18/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9025 - loss: 0.2217 - val_accuracy: 0.9118 - val_loss: 0.2792\n",
      "Epoch 19/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8997 - loss: 0.2222 - val_accuracy: 0.9044 - val_loss: 0.2722\n",
      "Epoch 20/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9025 - loss: 0.2194 - val_accuracy: 0.9118 - val_loss: 0.2889\n",
      "Epoch 21/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9071 - loss: 0.2181 - val_accuracy: 0.9154 - val_loss: 0.2779\n",
      "Epoch 22/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9062 - loss: 0.2129 - val_accuracy: 0.9118 - val_loss: 0.2862\n",
      "Epoch 23/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9098 - loss: 0.2107 - val_accuracy: 0.9118 - val_loss: 0.2882\n",
      "Epoch 24/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9098 - loss: 0.2074 - val_accuracy: 0.9118 - val_loss: 0.2945\n",
      "Epoch 25/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9108 - loss: 0.2053 - val_accuracy: 0.9044 - val_loss: 0.2980\n",
      "Epoch 26/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9200 - loss: 0.2039 - val_accuracy: 0.9044 - val_loss: 0.3039\n",
      "Epoch 27/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9108 - loss: 0.2012 - val_accuracy: 0.9007 - val_loss: 0.3011\n",
      "Epoch 28/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9172 - loss: 0.2007 - val_accuracy: 0.9044 - val_loss: 0.3059\n",
      "Epoch 29/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9172 - loss: 0.2026 - val_accuracy: 0.9007 - val_loss: 0.2818\n",
      "Epoch 30/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9246 - loss: 0.1919 - val_accuracy: 0.9044 - val_loss: 0.3149\n",
      "Epoch 31/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9200 - loss: 0.1922 - val_accuracy: 0.9154 - val_loss: 0.2903\n",
      "Epoch 32/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9209 - loss: 0.1931 - val_accuracy: 0.9007 - val_loss: 0.3155\n",
      "Epoch 33/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9218 - loss: 0.1886 - val_accuracy: 0.9007 - val_loss: 0.3126\n",
      "Epoch 34/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9236 - loss: 0.1851 - val_accuracy: 0.8934 - val_loss: 0.3125\n",
      "Epoch 35/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9209 - loss: 0.1874 - val_accuracy: 0.9081 - val_loss: 0.3152\n",
      "Epoch 36/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9181 - loss: 0.1848 - val_accuracy: 0.9007 - val_loss: 0.3143\n",
      "Epoch 37/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9190 - loss: 0.1859 - val_accuracy: 0.9044 - val_loss: 0.3236\n",
      "Epoch 38/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9292 - loss: 0.1797 - val_accuracy: 0.9007 - val_loss: 0.3203\n",
      "Epoch 39/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9292 - loss: 0.1745 - val_accuracy: 0.9007 - val_loss: 0.3187\n",
      "Epoch 40/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9301 - loss: 0.1730 - val_accuracy: 0.9081 - val_loss: 0.3148\n",
      "Epoch 41/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9347 - loss: 0.1708 - val_accuracy: 0.9044 - val_loss: 0.3214\n",
      "Epoch 42/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9310 - loss: 0.1686 - val_accuracy: 0.8897 - val_loss: 0.3385\n",
      "Epoch 43/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9282 - loss: 0.1686 - val_accuracy: 0.9007 - val_loss: 0.3276\n",
      "Epoch 44/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9282 - loss: 0.1646 - val_accuracy: 0.9081 - val_loss: 0.3351\n",
      "Epoch 45/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9310 - loss: 0.1648 - val_accuracy: 0.9044 - val_loss: 0.3230\n",
      "Epoch 46/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9301 - loss: 0.1631 - val_accuracy: 0.8971 - val_loss: 0.3405\n",
      "Epoch 47/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9310 - loss: 0.1619 - val_accuracy: 0.9044 - val_loss: 0.3388\n",
      "Epoch 48/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9365 - loss: 0.1549 - val_accuracy: 0.9007 - val_loss: 0.3575\n",
      "Epoch 49/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9356 - loss: 0.1584 - val_accuracy: 0.9007 - val_loss: 0.3609\n",
      "Epoch 50/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9347 - loss: 0.1541 - val_accuracy: 0.9007 - val_loss: 0.3643\n",
      "Epoch 51/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9402 - loss: 0.1514 - val_accuracy: 0.8971 - val_loss: 0.3601\n",
      "Epoch 52/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9393 - loss: 0.1484 - val_accuracy: 0.9007 - val_loss: 0.3543\n",
      "Epoch 53/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9430 - loss: 0.1440 - val_accuracy: 0.9007 - val_loss: 0.3729\n",
      "Epoch 54/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9411 - loss: 0.1436 - val_accuracy: 0.9007 - val_loss: 0.3714\n",
      "Epoch 55/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9448 - loss: 0.1404 - val_accuracy: 0.8897 - val_loss: 0.3917\n",
      "Epoch 56/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9384 - loss: 0.1435 - val_accuracy: 0.9081 - val_loss: 0.3539\n",
      "Epoch 57/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9448 - loss: 0.1409 - val_accuracy: 0.9118 - val_loss: 0.3466\n",
      "Epoch 58/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9448 - loss: 0.1372 - val_accuracy: 0.9007 - val_loss: 0.3737\n",
      "Epoch 59/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9503 - loss: 0.1356 - val_accuracy: 0.8971 - val_loss: 0.3801\n",
      "Epoch 60/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9476 - loss: 0.1312 - val_accuracy: 0.8971 - val_loss: 0.3935\n",
      "Epoch 61/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9522 - loss: 0.1328 - val_accuracy: 0.8934 - val_loss: 0.4172\n",
      "Epoch 62/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1317 - val_accuracy: 0.9007 - val_loss: 0.3732\n",
      "Epoch 63/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9494 - loss: 0.1281 - val_accuracy: 0.9007 - val_loss: 0.4018\n",
      "Epoch 64/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9512 - loss: 0.1249 - val_accuracy: 0.9081 - val_loss: 0.3828\n",
      "Epoch 65/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9522 - loss: 0.1245 - val_accuracy: 0.8971 - val_loss: 0.3909\n",
      "Epoch 66/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9531 - loss: 0.1216 - val_accuracy: 0.8934 - val_loss: 0.4120\n",
      "Epoch 67/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9568 - loss: 0.1186 - val_accuracy: 0.9044 - val_loss: 0.4180\n",
      "Epoch 68/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9540 - loss: 0.1196 - val_accuracy: 0.8897 - val_loss: 0.4142\n",
      "Epoch 69/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9503 - loss: 0.1195 - val_accuracy: 0.8897 - val_loss: 0.3992\n",
      "Epoch 70/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9522 - loss: 0.1192 - val_accuracy: 0.9044 - val_loss: 0.4005\n",
      "Epoch 71/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9531 - loss: 0.1132 - val_accuracy: 0.9044 - val_loss: 0.3864\n",
      "Epoch 72/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9577 - loss: 0.1114 - val_accuracy: 0.8971 - val_loss: 0.4361\n",
      "Epoch 73/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9577 - loss: 0.1104 - val_accuracy: 0.8971 - val_loss: 0.3994\n",
      "Epoch 74/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9641 - loss: 0.1091 - val_accuracy: 0.9007 - val_loss: 0.4100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9604 - loss: 0.1061 - val_accuracy: 0.8713 - val_loss: 0.4291\n",
      "Epoch 76/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9660 - loss: 0.1024 - val_accuracy: 0.9044 - val_loss: 0.4298\n",
      "Epoch 77/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9614 - loss: 0.1049 - val_accuracy: 0.9044 - val_loss: 0.4190\n",
      "Epoch 78/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9614 - loss: 0.1008 - val_accuracy: 0.8934 - val_loss: 0.4301\n",
      "Epoch 79/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9650 - loss: 0.0989 - val_accuracy: 0.8934 - val_loss: 0.4483\n",
      "Epoch 80/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9632 - loss: 0.0981 - val_accuracy: 0.8934 - val_loss: 0.4500\n",
      "Epoch 81/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9660 - loss: 0.0957 - val_accuracy: 0.9044 - val_loss: 0.4456\n",
      "Epoch 82/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9678 - loss: 0.0944 - val_accuracy: 0.9044 - val_loss: 0.4512\n",
      "Epoch 83/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9660 - loss: 0.0912 - val_accuracy: 0.8750 - val_loss: 0.5036\n",
      "Epoch 84/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9669 - loss: 0.0926 - val_accuracy: 0.9007 - val_loss: 0.4361\n",
      "Epoch 85/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9650 - loss: 0.0895 - val_accuracy: 0.9007 - val_loss: 0.4690\n",
      "Epoch 86/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9650 - loss: 0.0917 - val_accuracy: 0.8934 - val_loss: 0.4528\n",
      "Epoch 87/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9733 - loss: 0.0951 - val_accuracy: 0.9007 - val_loss: 0.4726\n",
      "Epoch 88/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9706 - loss: 0.0857 - val_accuracy: 0.9081 - val_loss: 0.4672\n",
      "Epoch 89/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9706 - loss: 0.0826 - val_accuracy: 0.8934 - val_loss: 0.4522\n",
      "Epoch 90/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9706 - loss: 0.0831 - val_accuracy: 0.8934 - val_loss: 0.4551\n",
      "Epoch 91/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9724 - loss: 0.0810 - val_accuracy: 0.8971 - val_loss: 0.4978\n",
      "Epoch 92/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9761 - loss: 0.0789 - val_accuracy: 0.8897 - val_loss: 0.4611\n",
      "Epoch 93/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9788 - loss: 0.0743 - val_accuracy: 0.8934 - val_loss: 0.4809\n",
      "Epoch 94/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9779 - loss: 0.0782 - val_accuracy: 0.8897 - val_loss: 0.4912\n",
      "Epoch 95/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9761 - loss: 0.0762 - val_accuracy: 0.8897 - val_loss: 0.5279\n",
      "Epoch 96/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9816 - loss: 0.0733 - val_accuracy: 0.8824 - val_loss: 0.5048\n",
      "Epoch 97/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9807 - loss: 0.0698 - val_accuracy: 0.8934 - val_loss: 0.5135\n",
      "Epoch 98/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9779 - loss: 0.0713 - val_accuracy: 0.9044 - val_loss: 0.4806\n",
      "Epoch 99/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9807 - loss: 0.0720 - val_accuracy: 0.8824 - val_loss: 0.4847\n",
      "Epoch 100/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9733 - loss: 0.0753 - val_accuracy: 0.8897 - val_loss: 0.4881\n",
      "Epoch 101/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9825 - loss: 0.0668 - val_accuracy: 0.9007 - val_loss: 0.4867\n",
      "Epoch 102/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9788 - loss: 0.0712 - val_accuracy: 0.9081 - val_loss: 0.4964\n",
      "Epoch 103/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9834 - loss: 0.0648 - val_accuracy: 0.8897 - val_loss: 0.5493\n",
      "Epoch 104/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9844 - loss: 0.0629 - val_accuracy: 0.9007 - val_loss: 0.5163\n",
      "Epoch 105/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9816 - loss: 0.0607 - val_accuracy: 0.8934 - val_loss: 0.5200\n",
      "Epoch 106/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.0616 - val_accuracy: 0.8934 - val_loss: 0.5192\n",
      "Epoch 107/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9880 - loss: 0.0579 - val_accuracy: 0.9007 - val_loss: 0.5406\n",
      "Epoch 108/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.0585 - val_accuracy: 0.9044 - val_loss: 0.5366\n",
      "Epoch 109/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9890 - loss: 0.0557 - val_accuracy: 0.8971 - val_loss: 0.5233\n",
      "Epoch 110/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9908 - loss: 0.0544 - val_accuracy: 0.8897 - val_loss: 0.5353\n",
      "Epoch 111/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.0548 - val_accuracy: 0.9007 - val_loss: 0.5462\n",
      "Epoch 112/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9880 - loss: 0.0523 - val_accuracy: 0.8897 - val_loss: 0.6005\n",
      "Epoch 113/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9862 - loss: 0.0538 - val_accuracy: 0.8934 - val_loss: 0.5172\n",
      "Epoch 114/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9899 - loss: 0.0499 - val_accuracy: 0.8787 - val_loss: 0.5219\n",
      "Epoch 115/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9880 - loss: 0.0488 - val_accuracy: 0.8934 - val_loss: 0.5783\n",
      "Epoch 116/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.0493 - val_accuracy: 0.9007 - val_loss: 0.5420\n",
      "Epoch 117/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9908 - loss: 0.0481 - val_accuracy: 0.8934 - val_loss: 0.5449\n",
      "Epoch 118/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.0498 - val_accuracy: 0.8824 - val_loss: 0.5726\n",
      "Epoch 119/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9871 - loss: 0.0520 - val_accuracy: 0.8860 - val_loss: 0.5696\n",
      "Epoch 120/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.0468 - val_accuracy: 0.8971 - val_loss: 0.5548\n",
      "Epoch 121/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9936 - loss: 0.0436 - val_accuracy: 0.8934 - val_loss: 0.6144\n",
      "Epoch 122/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9844 - loss: 0.0495 - val_accuracy: 0.9044 - val_loss: 0.5547\n",
      "Epoch 123/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9917 - loss: 0.0425 - val_accuracy: 0.9044 - val_loss: 0.5770\n",
      "Epoch 124/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9899 - loss: 0.0404 - val_accuracy: 0.8971 - val_loss: 0.5647\n",
      "Epoch 125/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9917 - loss: 0.0451 - val_accuracy: 0.8934 - val_loss: 0.6006\n",
      "Epoch 126/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.0416 - val_accuracy: 0.9118 - val_loss: 0.5755\n",
      "Epoch 127/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9908 - loss: 0.0440 - val_accuracy: 0.9007 - val_loss: 0.5918\n",
      "Epoch 128/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0406 - val_accuracy: 0.9044 - val_loss: 0.5830\n",
      "Epoch 129/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9945 - loss: 0.0396 - val_accuracy: 0.8971 - val_loss: 0.5902\n",
      "Epoch 130/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9917 - loss: 0.0374 - val_accuracy: 0.8971 - val_loss: 0.5999\n",
      "Epoch 131/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9926 - loss: 0.0375 - val_accuracy: 0.8897 - val_loss: 0.6206\n",
      "Epoch 132/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0361 - val_accuracy: 0.9007 - val_loss: 0.6197\n",
      "Epoch 133/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0352 - val_accuracy: 0.8860 - val_loss: 0.6332\n",
      "Epoch 134/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0335 - val_accuracy: 0.8934 - val_loss: 0.6231\n",
      "Epoch 135/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0338 - val_accuracy: 0.8934 - val_loss: 0.6046\n",
      "Epoch 136/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0338 - val_accuracy: 0.8934 - val_loss: 0.6396\n",
      "Epoch 137/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9926 - loss: 0.0338 - val_accuracy: 0.8897 - val_loss: 0.6204\n",
      "Epoch 138/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0322 - val_accuracy: 0.8824 - val_loss: 0.5978\n",
      "Epoch 139/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0327 - val_accuracy: 0.8934 - val_loss: 0.6807\n",
      "Epoch 140/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.0381 - val_accuracy: 0.8971 - val_loss: 0.6876\n",
      "Epoch 141/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9963 - loss: 0.0326 - val_accuracy: 0.8971 - val_loss: 0.6511\n",
      "Epoch 142/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0289 - val_accuracy: 0.8897 - val_loss: 0.6850\n",
      "Epoch 143/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0305 - val_accuracy: 0.8860 - val_loss: 0.6287\n",
      "Epoch 144/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9926 - loss: 0.0325 - val_accuracy: 0.8897 - val_loss: 0.6251\n",
      "Epoch 145/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0300 - val_accuracy: 0.8934 - val_loss: 0.7103\n",
      "Epoch 146/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0272 - val_accuracy: 0.8934 - val_loss: 0.6711\n",
      "Epoch 147/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9945 - loss: 0.0274 - val_accuracy: 0.8971 - val_loss: 0.6563\n",
      "Epoch 148/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0263 - val_accuracy: 0.8934 - val_loss: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0255 - val_accuracy: 0.8897 - val_loss: 0.6714\n",
      "Epoch 150/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.9972 - loss: 0.0265 - val_accuracy: 0.8860 - val_loss: 0.6780\n",
      "Epoch 151/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0240 - val_accuracy: 0.8787 - val_loss: 0.7260\n",
      "Epoch 152/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9936 - loss: 0.0247 - val_accuracy: 0.8897 - val_loss: 0.6852\n",
      "Epoch 153/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0266 - val_accuracy: 0.9044 - val_loss: 0.6566\n",
      "Epoch 154/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0244 - val_accuracy: 0.8934 - val_loss: 0.6918\n",
      "Epoch 155/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0220 - val_accuracy: 0.8971 - val_loss: 0.7110\n",
      "Epoch 156/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0229 - val_accuracy: 0.8971 - val_loss: 0.7253\n",
      "Epoch 157/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9945 - loss: 0.0247 - val_accuracy: 0.8787 - val_loss: 0.6906\n",
      "Epoch 158/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0231 - val_accuracy: 0.8934 - val_loss: 0.7259\n",
      "Epoch 159/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9954 - loss: 0.0252 - val_accuracy: 0.8897 - val_loss: 0.7215\n",
      "Epoch 160/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0209 - val_accuracy: 0.8971 - val_loss: 0.7430\n",
      "Epoch 161/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0206 - val_accuracy: 0.8860 - val_loss: 0.7017\n",
      "Epoch 162/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0190 - val_accuracy: 0.8897 - val_loss: 0.7368\n",
      "Epoch 163/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0194 - val_accuracy: 0.8787 - val_loss: 0.7333\n",
      "Epoch 164/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0192 - val_accuracy: 0.8934 - val_loss: 0.7509\n",
      "Epoch 165/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0208 - val_accuracy: 0.8934 - val_loss: 0.7447\n",
      "Epoch 166/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0192 - val_accuracy: 0.8787 - val_loss: 0.7550\n",
      "Epoch 167/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0260 - val_accuracy: 0.8713 - val_loss: 0.7852\n",
      "Epoch 168/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0283 - val_accuracy: 0.8860 - val_loss: 0.8001\n",
      "Epoch 169/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0312 - val_accuracy: 0.8750 - val_loss: 0.7209\n",
      "Epoch 170/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9908 - loss: 0.0290 - val_accuracy: 0.8676 - val_loss: 0.7740\n",
      "Epoch 171/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0187 - val_accuracy: 0.8713 - val_loss: 0.7708\n",
      "Epoch 172/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9963 - loss: 0.0204 - val_accuracy: 0.8824 - val_loss: 0.7641\n",
      "Epoch 173/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0185 - val_accuracy: 0.8860 - val_loss: 0.7824\n",
      "Epoch 174/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0188 - val_accuracy: 0.8713 - val_loss: 0.7675\n",
      "Epoch 175/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0165 - val_accuracy: 0.8897 - val_loss: 0.7365\n",
      "Epoch 176/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0160 - val_accuracy: 0.8897 - val_loss: 0.7756\n",
      "Epoch 177/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0168 - val_accuracy: 0.8934 - val_loss: 0.8603\n",
      "Epoch 178/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0168 - val_accuracy: 0.8750 - val_loss: 0.7961\n",
      "Epoch 179/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9972 - loss: 0.0161 - val_accuracy: 0.8897 - val_loss: 0.8193\n",
      "Epoch 180/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0173 - val_accuracy: 0.8897 - val_loss: 0.7982\n",
      "Epoch 181/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0153 - val_accuracy: 0.8860 - val_loss: 0.8200\n",
      "Epoch 182/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9982 - loss: 0.0143 - val_accuracy: 0.8934 - val_loss: 0.8688\n",
      "Epoch 183/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0142 - val_accuracy: 0.8713 - val_loss: 0.8270\n",
      "Epoch 184/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9972 - loss: 0.0159 - val_accuracy: 0.8860 - val_loss: 0.8429\n",
      "Epoch 185/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0169 - val_accuracy: 0.8824 - val_loss: 0.8309\n",
      "Epoch 186/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9991 - loss: 0.0135 - val_accuracy: 0.8640 - val_loss: 0.8442\n",
      "Epoch 187/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9908 - loss: 0.0296 - val_accuracy: 0.8603 - val_loss: 0.8811\n",
      "Epoch 188/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0168 - val_accuracy: 0.8860 - val_loss: 0.7815\n",
      "Epoch 189/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0132 - val_accuracy: 0.8897 - val_loss: 0.8808\n",
      "Epoch 190/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0150 - val_accuracy: 0.8824 - val_loss: 0.8483\n",
      "Epoch 191/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 0.8860 - val_loss: 0.8559\n",
      "Epoch 192/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0121 - val_accuracy: 0.8787 - val_loss: 0.8162\n",
      "Epoch 193/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0115 - val_accuracy: 0.8824 - val_loss: 0.8597\n",
      "Epoch 194/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0131 - val_accuracy: 0.8713 - val_loss: 0.8407\n",
      "Epoch 195/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0112 - val_accuracy: 0.8824 - val_loss: 0.8540\n",
      "Epoch 196/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0115 - val_accuracy: 0.8787 - val_loss: 0.8581\n",
      "Epoch 197/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0119 - val_accuracy: 0.8860 - val_loss: 0.8850\n",
      "Epoch 198/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0129 - val_accuracy: 0.8860 - val_loss: 0.8352\n",
      "Epoch 199/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0115 - val_accuracy: 0.8824 - val_loss: 0.8950\n",
      "Epoch 200/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.8897 - val_loss: 0.9047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72a84f3e3740>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model = build_model(X_train.shape[1])\n",
    "# trains the neural network\n",
    "# epochs = 200 -> Feeds training data through the model 200 times\n",
    "# give the model unseen data (validation data) to evaluate after each epoch\n",
    "# the model trains on mini-batches of 16 examples at a time\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=16, verbose=2) # -> Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89c4bd",
   "metadata": {},
   "source": [
    "###### Training with the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9381a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 - 2s - 29ms/step - accuracy: 0.6081 - loss: 0.7775 - val_accuracy: 0.8382 - val_loss: 0.6094 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.7369 - loss: 0.6007 - val_accuracy: 0.8750 - val_loss: 0.5336 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.7912 - loss: 0.5312 - val_accuracy: 0.8603 - val_loss: 0.4670 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8372 - loss: 0.4565 - val_accuracy: 0.8750 - val_loss: 0.4186 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8482 - loss: 0.4173 - val_accuracy: 0.8860 - val_loss: 0.3838 - learning_rate: 1.0000e-03\n",
      "Epoch 6/200\n",
      "68/68 - 1s - 8ms/step - accuracy: 0.8602 - loss: 0.3885 - val_accuracy: 0.8860 - val_loss: 0.3555 - learning_rate: 1.0000e-03\n",
      "Epoch 7/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.8500 - loss: 0.4019 - val_accuracy: 0.8787 - val_loss: 0.3498 - learning_rate: 1.0000e-03\n",
      "Epoch 8/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.8694 - loss: 0.3813 - val_accuracy: 0.8860 - val_loss: 0.3387 - learning_rate: 1.0000e-03\n",
      "Epoch 9/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.8730 - loss: 0.3721 - val_accuracy: 0.8897 - val_loss: 0.3315 - learning_rate: 1.0000e-03\n",
      "Epoch 10/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.8666 - loss: 0.3643 - val_accuracy: 0.8934 - val_loss: 0.3366 - learning_rate: 1.0000e-03\n",
      "Epoch 11/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.8703 - loss: 0.3538 - val_accuracy: 0.8934 - val_loss: 0.3273 - learning_rate: 1.0000e-03\n",
      "Epoch 12/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.8822 - loss: 0.3416 - val_accuracy: 0.9007 - val_loss: 0.3262 - learning_rate: 1.0000e-03\n",
      "Epoch 13/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.8767 - loss: 0.3527 - val_accuracy: 0.9044 - val_loss: 0.3232 - learning_rate: 1.0000e-03\n",
      "Epoch 14/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8786 - loss: 0.3523 - val_accuracy: 0.9007 - val_loss: 0.3245 - learning_rate: 1.0000e-03\n",
      "Epoch 15/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8868 - loss: 0.3291 - val_accuracy: 0.9044 - val_loss: 0.3259 - learning_rate: 1.0000e-03\n",
      "Epoch 16/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8758 - loss: 0.3462 - val_accuracy: 0.8971 - val_loss: 0.3154 - learning_rate: 1.0000e-03\n",
      "Epoch 17/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8776 - loss: 0.3438 - val_accuracy: 0.9007 - val_loss: 0.3116 - learning_rate: 1.0000e-03\n",
      "Epoch 18/200\n",
      "68/68 - 0s - 7ms/step - accuracy: 0.8795 - loss: 0.3539 - val_accuracy: 0.9007 - val_loss: 0.3125 - learning_rate: 1.0000e-03\n",
      "Epoch 19/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8878 - loss: 0.3319 - val_accuracy: 0.9154 - val_loss: 0.3078 - learning_rate: 1.0000e-03\n",
      "Epoch 20/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8896 - loss: 0.3102 - val_accuracy: 0.9081 - val_loss: 0.3015 - learning_rate: 1.0000e-03\n",
      "Epoch 21/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8767 - loss: 0.3364 - val_accuracy: 0.9081 - val_loss: 0.3138 - learning_rate: 1.0000e-03\n",
      "Epoch 22/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8813 - loss: 0.3228 - val_accuracy: 0.9044 - val_loss: 0.3100 - learning_rate: 1.0000e-03\n",
      "Epoch 23/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8684 - loss: 0.3372 - val_accuracy: 0.9044 - val_loss: 0.3022 - learning_rate: 1.0000e-03\n",
      "Epoch 24/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.8832 - loss: 0.3157 - val_accuracy: 0.9044 - val_loss: 0.3041 - learning_rate: 1.0000e-03\n",
      "Epoch 25/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8740 - loss: 0.3216 - val_accuracy: 0.9044 - val_loss: 0.3057 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8721 - loss: 0.3215 - val_accuracy: 0.9081 - val_loss: 0.3045 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8914 - loss: 0.3058 - val_accuracy: 0.9044 - val_loss: 0.3045 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8841 - loss: 0.3175 - val_accuracy: 0.9044 - val_loss: 0.3083 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72a84f3226f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model1 = build_model1(X_train.shape[1])\n",
    "# trains the neural network\n",
    "# epochs = 200 -> Feeds training data through the model 200 times\n",
    "# give the model unseen data (validation data) to evaluate after each epoch\n",
    "# the model trains on mini-batches of 16 examples at a time\n",
    "model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=16, verbose=2, callbacks=[es, rlr]) # -> Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867222f9",
   "metadata": {},
   "source": [
    "#### Train ANN with the dataframe which has the row with the right label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5328b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get from Hadoop the version with the old label\n",
    "clean_old_df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/CA1/ACID/clean/winequality-red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c40dad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace invalid characters with underscores, sanitize the columns\n",
    "for c in clean_old_df.columns:\n",
    "    clean_old_df = clean_old_df.withColumnRenamed(c, c.strip().lower().replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31e6c784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|255|    0|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 113:============================================>          (40 + 4) / 50]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check if the old version has the label with the old value, it is 0, so it is correct\n",
    "clean_old_df.select(\"id\", \"label\").where(F.col(\"id\")==bad_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d18682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  184|\n",
      "|    0| 1175|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how many 0s and 1s are in the dataset using Spark\n",
    "clean_old_df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b17c9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to_numpy\n",
    "X1, y1 = to_numpy(clean_old_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c1b761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(1174), np.int64(1): np.int64(185)}\n"
     ]
    }
   ],
   "source": [
    "# Check how many 0s and 1s are in the dataset using numpy\n",
    "unique, counts = np.unique(y, return_counts=True) \n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c150158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing subsets\n",
    "# test_size= 0.2 -> 20% of the data will go to the test set, and 80% will go to the training set\n",
    "# If you have 1,599 samples: Training set is ~1,279 rows and Test set is 320 rows approximately\n",
    "# Ensure the same split every time you run the code, otherwise different 20% of rows go to X_test1 each time \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e3494af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import resample\n",
    "#import pandas as pd\n",
    "\n",
    "#dfnew = pd.DataFrame(X_train1,columns=feature_cols)\n",
    "#dfnew['label'] = y_train1\n",
    "\n",
    "#majority = dfnew[dfnew.label == 0]\n",
    "#minority = dfnew[dfnew.label == 1]\n",
    "\n",
    "#minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "#df_balanced = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "# Shuffle the dataset to mix both classes\n",
    "#df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#X_train1 = df_balanced[feature_cols].to_numpy(dtype=np.float32)\n",
    "#y_train1 = df_balanced[\"label\"].to_numpy(dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70cdfde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.338547</td>\n",
       "      <td>0.530603</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>2.527691</td>\n",
       "      <td>0.088157</td>\n",
       "      <td>16.013340</td>\n",
       "      <td>46.659153</td>\n",
       "      <td>0.996735</td>\n",
       "      <td>3.309908</td>\n",
       "      <td>0.656734</td>\n",
       "      <td>10.439558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.730869</td>\n",
       "      <td>0.185112</td>\n",
       "      <td>0.195892</td>\n",
       "      <td>1.374252</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>10.605497</td>\n",
       "      <td>32.942955</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.153877</td>\n",
       "      <td>0.161211</td>\n",
       "      <td>1.069283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997860</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1087.000000  1087.000000  1087.000000  1087.000000  1087.000000   \n",
       "mean      8.338547     0.530603     0.271739     2.527691     0.088157   \n",
       "std       1.730869     0.185112     0.195892     1.374252     0.049906   \n",
       "min       4.600000     0.120000     0.000000     0.900000     0.012000   \n",
       "25%       7.100000     0.390000     0.090000     1.900000     0.070000   \n",
       "50%       7.900000     0.520000     0.260000     2.200000     0.079000   \n",
       "75%       9.300000     0.642500     0.430000     2.600000     0.091000   \n",
       "max      15.900000     1.580000     1.000000    15.500000     0.611000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1087.000000  1087.000000  1087.000000  1087.000000  1087.000000   \n",
       "mean     16.013340    46.659153     0.996735     3.309908     0.656734   \n",
       "std      10.605497    32.942955     0.001863     0.153877     0.161211   \n",
       "min       1.000000     6.000000     0.990070     2.740000     0.370000   \n",
       "25%       7.000000    22.000000     0.995600     3.210000     0.550000   \n",
       "50%      13.000000    38.000000     0.996700     3.310000     0.620000   \n",
       "75%      22.000000    62.000000     0.997860     3.400000     0.730000   \n",
       "max      72.000000   289.000000     1.003690     4.010000     2.000000   \n",
       "\n",
       "                10  \n",
       "count  1087.000000  \n",
       "mean     10.439558  \n",
       "std       1.069283  \n",
       "min       8.400000  \n",
       "25%       9.500000  \n",
       "50%      10.200000  \n",
       "75%      11.100000  \n",
       "max      14.900000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap the NumPy array X_train1 inside a pandas dataFrame to call describe\n",
    "# we check values min and max to verify if they have different scales\n",
    "pd.DataFrame(X_train1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29d6fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 11) (272, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1.shape, X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8edccb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize because different features have different scales, and we want them all to have equal importance for the model.\n",
    "# fit on the training set, use the same mean and std from training data to scale the test set\n",
    "# it means that both datasets are on the same scale\n",
    "sc = StandardScaler().fit(X_train1)\n",
    "X_train1, X_test1 = sc.transform(X_train1), sc.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e1d49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils.class_weight import compute_class_weight\n",
    "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train1), y=y_train1)\n",
    "#class_weights = dict(enumerate(class_weights))\n",
    "#print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a48247",
   "metadata": {},
   "source": [
    "###### Training with the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef36c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/venvs/spark-delta/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 1s - 14ms/step - accuracy: 0.8611 - loss: 0.3795 - val_accuracy: 0.8750 - val_loss: 0.3376\n",
      "Epoch 2/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8841 - loss: 0.2956 - val_accuracy: 0.8860 - val_loss: 0.3012\n",
      "Epoch 3/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8795 - loss: 0.2767 - val_accuracy: 0.8897 - val_loss: 0.2879\n",
      "Epoch 4/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.8822 - loss: 0.2675 - val_accuracy: 0.8934 - val_loss: 0.2747\n",
      "Epoch 5/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.8850 - loss: 0.2622 - val_accuracy: 0.8934 - val_loss: 0.2800\n",
      "Epoch 6/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8924 - loss: 0.2567 - val_accuracy: 0.9007 - val_loss: 0.2719\n",
      "Epoch 7/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8887 - loss: 0.2522 - val_accuracy: 0.8860 - val_loss: 0.2824\n",
      "Epoch 8/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.8850 - loss: 0.2503 - val_accuracy: 0.9007 - val_loss: 0.2632\n",
      "Epoch 9/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8905 - loss: 0.2459 - val_accuracy: 0.9044 - val_loss: 0.2622\n",
      "Epoch 10/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8914 - loss: 0.2464 - val_accuracy: 0.9007 - val_loss: 0.2598\n",
      "Epoch 11/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8924 - loss: 0.2411 - val_accuracy: 0.8934 - val_loss: 0.2638\n",
      "Epoch 12/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8914 - loss: 0.2380 - val_accuracy: 0.8934 - val_loss: 0.2787\n",
      "Epoch 13/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8924 - loss: 0.2353 - val_accuracy: 0.8971 - val_loss: 0.2641\n",
      "Epoch 14/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9025 - loss: 0.2324 - val_accuracy: 0.8934 - val_loss: 0.2763\n",
      "Epoch 15/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9034 - loss: 0.2307 - val_accuracy: 0.9044 - val_loss: 0.2574\n",
      "Epoch 16/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9052 - loss: 0.2255 - val_accuracy: 0.8934 - val_loss: 0.2749\n",
      "Epoch 17/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8988 - loss: 0.2233 - val_accuracy: 0.8934 - val_loss: 0.2730\n",
      "Epoch 18/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9034 - loss: 0.2217 - val_accuracy: 0.8971 - val_loss: 0.2569\n",
      "Epoch 19/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9071 - loss: 0.2195 - val_accuracy: 0.8934 - val_loss: 0.2726\n",
      "Epoch 20/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9043 - loss: 0.2164 - val_accuracy: 0.9044 - val_loss: 0.2676\n",
      "Epoch 21/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9080 - loss: 0.2114 - val_accuracy: 0.8934 - val_loss: 0.2782\n",
      "Epoch 22/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9089 - loss: 0.2115 - val_accuracy: 0.8971 - val_loss: 0.2719\n",
      "Epoch 23/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9108 - loss: 0.2086 - val_accuracy: 0.8971 - val_loss: 0.2737\n",
      "Epoch 24/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9135 - loss: 0.2055 - val_accuracy: 0.9044 - val_loss: 0.2759\n",
      "Epoch 25/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9163 - loss: 0.2031 - val_accuracy: 0.8971 - val_loss: 0.2660\n",
      "Epoch 26/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9172 - loss: 0.2004 - val_accuracy: 0.9007 - val_loss: 0.2719\n",
      "Epoch 27/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9135 - loss: 0.1994 - val_accuracy: 0.9007 - val_loss: 0.2810\n",
      "Epoch 28/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9172 - loss: 0.1975 - val_accuracy: 0.9081 - val_loss: 0.2774\n",
      "Epoch 29/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9264 - loss: 0.1896 - val_accuracy: 0.8934 - val_loss: 0.2764\n",
      "Epoch 30/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9190 - loss: 0.1937 - val_accuracy: 0.9044 - val_loss: 0.2868\n",
      "Epoch 31/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9264 - loss: 0.1875 - val_accuracy: 0.9007 - val_loss: 0.2778\n",
      "Epoch 32/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9292 - loss: 0.1835 - val_accuracy: 0.9118 - val_loss: 0.2809\n",
      "Epoch 33/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9227 - loss: 0.1824 - val_accuracy: 0.8897 - val_loss: 0.2919\n",
      "Epoch 34/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9301 - loss: 0.1799 - val_accuracy: 0.9118 - val_loss: 0.2874\n",
      "Epoch 35/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9301 - loss: 0.1792 - val_accuracy: 0.9007 - val_loss: 0.2914\n",
      "Epoch 36/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9301 - loss: 0.1749 - val_accuracy: 0.9044 - val_loss: 0.2769\n",
      "Epoch 37/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9292 - loss: 0.1745 - val_accuracy: 0.9044 - val_loss: 0.2851\n",
      "Epoch 38/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9282 - loss: 0.1723 - val_accuracy: 0.9154 - val_loss: 0.2937\n",
      "Epoch 39/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9246 - loss: 0.1705 - val_accuracy: 0.9007 - val_loss: 0.2866\n",
      "Epoch 40/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9347 - loss: 0.1658 - val_accuracy: 0.8971 - val_loss: 0.3071\n",
      "Epoch 41/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9374 - loss: 0.1629 - val_accuracy: 0.9044 - val_loss: 0.2978\n",
      "Epoch 42/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9374 - loss: 0.1597 - val_accuracy: 0.8934 - val_loss: 0.3032\n",
      "Epoch 43/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9374 - loss: 0.1591 - val_accuracy: 0.9007 - val_loss: 0.3006\n",
      "Epoch 44/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9374 - loss: 0.1567 - val_accuracy: 0.9154 - val_loss: 0.2942\n",
      "Epoch 45/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9347 - loss: 0.1543 - val_accuracy: 0.9044 - val_loss: 0.2832\n",
      "Epoch 46/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9393 - loss: 0.1541 - val_accuracy: 0.8934 - val_loss: 0.2969\n",
      "Epoch 47/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9466 - loss: 0.1497 - val_accuracy: 0.9081 - val_loss: 0.2928\n",
      "Epoch 48/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9420 - loss: 0.1499 - val_accuracy: 0.9118 - val_loss: 0.2909\n",
      "Epoch 49/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9411 - loss: 0.1455 - val_accuracy: 0.9007 - val_loss: 0.2873\n",
      "Epoch 50/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9439 - loss: 0.1456 - val_accuracy: 0.9044 - val_loss: 0.3032\n",
      "Epoch 51/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9448 - loss: 0.1429 - val_accuracy: 0.9007 - val_loss: 0.3067\n",
      "Epoch 52/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9466 - loss: 0.1410 - val_accuracy: 0.9154 - val_loss: 0.3067\n",
      "Epoch 53/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9476 - loss: 0.1380 - val_accuracy: 0.9118 - val_loss: 0.3009\n",
      "Epoch 54/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9485 - loss: 0.1358 - val_accuracy: 0.9007 - val_loss: 0.3095\n",
      "Epoch 55/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9494 - loss: 0.1353 - val_accuracy: 0.8934 - val_loss: 0.3168\n",
      "Epoch 56/200\n",
      "68/68 - 1s - 20ms/step - accuracy: 0.9549 - loss: 0.1323 - val_accuracy: 0.9044 - val_loss: 0.3141\n",
      "Epoch 57/200\n",
      "68/68 - 3s - 48ms/step - accuracy: 0.9466 - loss: 0.1331 - val_accuracy: 0.8971 - val_loss: 0.3215\n",
      "Epoch 58/200\n",
      "68/68 - 4s - 55ms/step - accuracy: 0.9485 - loss: 0.1263 - val_accuracy: 0.9081 - val_loss: 0.3160\n",
      "Epoch 59/200\n",
      "68/68 - 3s - 38ms/step - accuracy: 0.9503 - loss: 0.1248 - val_accuracy: 0.8934 - val_loss: 0.3223\n",
      "Epoch 60/200\n",
      "68/68 - 2s - 31ms/step - accuracy: 0.9549 - loss: 0.1230 - val_accuracy: 0.9007 - val_loss: 0.3308\n",
      "Epoch 61/200\n",
      "68/68 - 2s - 33ms/step - accuracy: 0.9531 - loss: 0.1221 - val_accuracy: 0.9081 - val_loss: 0.3336\n",
      "Epoch 62/200\n",
      "68/68 - 3s - 38ms/step - accuracy: 0.9494 - loss: 0.1245 - val_accuracy: 0.9007 - val_loss: 0.3331\n",
      "Epoch 63/200\n",
      "68/68 - 2s - 33ms/step - accuracy: 0.9540 - loss: 0.1198 - val_accuracy: 0.8934 - val_loss: 0.3193\n",
      "Epoch 64/200\n",
      "68/68 - 2s - 34ms/step - accuracy: 0.9586 - loss: 0.1132 - val_accuracy: 0.9044 - val_loss: 0.3474\n",
      "Epoch 65/200\n",
      "68/68 - 2s - 29ms/step - accuracy: 0.9568 - loss: 0.1129 - val_accuracy: 0.9007 - val_loss: 0.3401\n",
      "Epoch 66/200\n",
      "68/68 - 2s - 26ms/step - accuracy: 0.9577 - loss: 0.1101 - val_accuracy: 0.9007 - val_loss: 0.3226\n",
      "Epoch 67/200\n",
      "68/68 - 2s - 35ms/step - accuracy: 0.9641 - loss: 0.1079 - val_accuracy: 0.9044 - val_loss: 0.3438\n",
      "Epoch 68/200\n",
      "68/68 - 3s - 41ms/step - accuracy: 0.9568 - loss: 0.1070 - val_accuracy: 0.9007 - val_loss: 0.3305\n",
      "Epoch 69/200\n",
      "68/68 - 2s - 31ms/step - accuracy: 0.9623 - loss: 0.1059 - val_accuracy: 0.9044 - val_loss: 0.3516\n",
      "Epoch 70/200\n",
      "68/68 - 2s - 36ms/step - accuracy: 0.9623 - loss: 0.1057 - val_accuracy: 0.8934 - val_loss: 0.3391\n",
      "Epoch 71/200\n",
      "68/68 - 3s - 45ms/step - accuracy: 0.9623 - loss: 0.1065 - val_accuracy: 0.8934 - val_loss: 0.3363\n",
      "Epoch 72/200\n",
      "68/68 - 2s - 37ms/step - accuracy: 0.9660 - loss: 0.0999 - val_accuracy: 0.9081 - val_loss: 0.3236\n",
      "Epoch 73/200\n",
      "68/68 - 2s - 34ms/step - accuracy: 0.9669 - loss: 0.0980 - val_accuracy: 0.9007 - val_loss: 0.3634\n",
      "Epoch 74/200\n",
      "68/68 - 3s - 39ms/step - accuracy: 0.9660 - loss: 0.0992 - val_accuracy: 0.8971 - val_loss: 0.3456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "68/68 - 1s - 20ms/step - accuracy: 0.9660 - loss: 0.0950 - val_accuracy: 0.8971 - val_loss: 0.3339\n",
      "Epoch 76/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9669 - loss: 0.0969 - val_accuracy: 0.9044 - val_loss: 0.3640\n",
      "Epoch 77/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9706 - loss: 0.0903 - val_accuracy: 0.9044 - val_loss: 0.3483\n",
      "Epoch 78/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9752 - loss: 0.0872 - val_accuracy: 0.8824 - val_loss: 0.3715\n",
      "Epoch 79/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9687 - loss: 0.0868 - val_accuracy: 0.8934 - val_loss: 0.3778\n",
      "Epoch 80/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9706 - loss: 0.0890 - val_accuracy: 0.9007 - val_loss: 0.3664\n",
      "Epoch 81/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9752 - loss: 0.0843 - val_accuracy: 0.9044 - val_loss: 0.3486\n",
      "Epoch 82/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9752 - loss: 0.0833 - val_accuracy: 0.9044 - val_loss: 0.4008\n",
      "Epoch 83/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9706 - loss: 0.0852 - val_accuracy: 0.9007 - val_loss: 0.3770\n",
      "Epoch 84/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9761 - loss: 0.0795 - val_accuracy: 0.8860 - val_loss: 0.3740\n",
      "Epoch 85/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9715 - loss: 0.0832 - val_accuracy: 0.9081 - val_loss: 0.3978\n",
      "Epoch 86/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9752 - loss: 0.0762 - val_accuracy: 0.8971 - val_loss: 0.3785\n",
      "Epoch 87/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9761 - loss: 0.0758 - val_accuracy: 0.9081 - val_loss: 0.3864\n",
      "Epoch 88/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9761 - loss: 0.0742 - val_accuracy: 0.8971 - val_loss: 0.3880\n",
      "Epoch 89/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9761 - loss: 0.0741 - val_accuracy: 0.8971 - val_loss: 0.3790\n",
      "Epoch 90/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9770 - loss: 0.0713 - val_accuracy: 0.8971 - val_loss: 0.4369\n",
      "Epoch 91/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9770 - loss: 0.0716 - val_accuracy: 0.9007 - val_loss: 0.3766\n",
      "Epoch 92/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9779 - loss: 0.0710 - val_accuracy: 0.8971 - val_loss: 0.4272\n",
      "Epoch 93/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9752 - loss: 0.0699 - val_accuracy: 0.8971 - val_loss: 0.4100\n",
      "Epoch 94/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9788 - loss: 0.0674 - val_accuracy: 0.8934 - val_loss: 0.4288\n",
      "Epoch 95/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9807 - loss: 0.0641 - val_accuracy: 0.8934 - val_loss: 0.3938\n",
      "Epoch 96/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9816 - loss: 0.0643 - val_accuracy: 0.8934 - val_loss: 0.4055\n",
      "Epoch 97/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9880 - loss: 0.0614 - val_accuracy: 0.8934 - val_loss: 0.4023\n",
      "Epoch 98/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9798 - loss: 0.0613 - val_accuracy: 0.8934 - val_loss: 0.4192\n",
      "Epoch 99/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.0592 - val_accuracy: 0.9044 - val_loss: 0.4116\n",
      "Epoch 100/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.9779 - loss: 0.0644 - val_accuracy: 0.9007 - val_loss: 0.3877\n",
      "Epoch 101/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9844 - loss: 0.0578 - val_accuracy: 0.8971 - val_loss: 0.4010\n",
      "Epoch 102/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9880 - loss: 0.0560 - val_accuracy: 0.8897 - val_loss: 0.4501\n",
      "Epoch 103/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9880 - loss: 0.0558 - val_accuracy: 0.9007 - val_loss: 0.4371\n",
      "Epoch 104/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9834 - loss: 0.0540 - val_accuracy: 0.9007 - val_loss: 0.4309\n",
      "Epoch 105/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.9871 - loss: 0.0537 - val_accuracy: 0.8971 - val_loss: 0.4477\n",
      "Epoch 106/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.9908 - loss: 0.0498 - val_accuracy: 0.9007 - val_loss: 0.4397\n",
      "Epoch 107/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9853 - loss: 0.0514 - val_accuracy: 0.9007 - val_loss: 0.4260\n",
      "Epoch 108/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9917 - loss: 0.0488 - val_accuracy: 0.9081 - val_loss: 0.4336\n",
      "Epoch 109/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9871 - loss: 0.0511 - val_accuracy: 0.8897 - val_loss: 0.4502\n",
      "Epoch 110/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9880 - loss: 0.0485 - val_accuracy: 0.8897 - val_loss: 0.4378\n",
      "Epoch 111/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.0488 - val_accuracy: 0.9007 - val_loss: 0.4636\n",
      "Epoch 112/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.0453 - val_accuracy: 0.9044 - val_loss: 0.4925\n",
      "Epoch 113/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9890 - loss: 0.0470 - val_accuracy: 0.8971 - val_loss: 0.5308\n",
      "Epoch 114/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9908 - loss: 0.0453 - val_accuracy: 0.8934 - val_loss: 0.4687\n",
      "Epoch 115/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9899 - loss: 0.0449 - val_accuracy: 0.8934 - val_loss: 0.4619\n",
      "Epoch 116/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0421 - val_accuracy: 0.8971 - val_loss: 0.4965\n",
      "Epoch 117/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9908 - loss: 0.0424 - val_accuracy: 0.8971 - val_loss: 0.4575\n",
      "Epoch 118/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9945 - loss: 0.0439 - val_accuracy: 0.8897 - val_loss: 0.5008\n",
      "Epoch 119/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9890 - loss: 0.0420 - val_accuracy: 0.8824 - val_loss: 0.5027\n",
      "Epoch 120/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9926 - loss: 0.0402 - val_accuracy: 0.8934 - val_loss: 0.5119\n",
      "Epoch 121/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9917 - loss: 0.0397 - val_accuracy: 0.9007 - val_loss: 0.4441\n",
      "Epoch 122/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0389 - val_accuracy: 0.8860 - val_loss: 0.4903\n",
      "Epoch 123/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9908 - loss: 0.0391 - val_accuracy: 0.8897 - val_loss: 0.5133\n",
      "Epoch 124/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9926 - loss: 0.0372 - val_accuracy: 0.8860 - val_loss: 0.4761\n",
      "Epoch 125/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9926 - loss: 0.0368 - val_accuracy: 0.8934 - val_loss: 0.4933\n",
      "Epoch 126/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0343 - val_accuracy: 0.8824 - val_loss: 0.5041\n",
      "Epoch 127/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0348 - val_accuracy: 0.8860 - val_loss: 0.5545\n",
      "Epoch 128/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0361 - val_accuracy: 0.8860 - val_loss: 0.5642\n",
      "Epoch 129/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9917 - loss: 0.0373 - val_accuracy: 0.8824 - val_loss: 0.5849\n",
      "Epoch 130/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0328 - val_accuracy: 0.8971 - val_loss: 0.5235\n",
      "Epoch 131/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0329 - val_accuracy: 0.8897 - val_loss: 0.5200\n",
      "Epoch 132/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9963 - loss: 0.0325 - val_accuracy: 0.8860 - val_loss: 0.5077\n",
      "Epoch 133/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0322 - val_accuracy: 0.8897 - val_loss: 0.5205\n",
      "Epoch 134/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9963 - loss: 0.0302 - val_accuracy: 0.8934 - val_loss: 0.5378\n",
      "Epoch 135/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9954 - loss: 0.0288 - val_accuracy: 0.8860 - val_loss: 0.5731\n",
      "Epoch 136/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0302 - val_accuracy: 0.8934 - val_loss: 0.5466\n",
      "Epoch 137/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9936 - loss: 0.0290 - val_accuracy: 0.8934 - val_loss: 0.5350\n",
      "Epoch 138/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0280 - val_accuracy: 0.8897 - val_loss: 0.5484\n",
      "Epoch 139/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0285 - val_accuracy: 0.8934 - val_loss: 0.5578\n",
      "Epoch 140/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9926 - loss: 0.0267 - val_accuracy: 0.9044 - val_loss: 0.4919\n",
      "Epoch 141/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9936 - loss: 0.0273 - val_accuracy: 0.8934 - val_loss: 0.5158\n",
      "Epoch 142/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0262 - val_accuracy: 0.8897 - val_loss: 0.5668\n",
      "Epoch 143/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9963 - loss: 0.0254 - val_accuracy: 0.8824 - val_loss: 0.5709\n",
      "Epoch 144/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9954 - loss: 0.0256 - val_accuracy: 0.8860 - val_loss: 0.5735\n",
      "Epoch 145/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0270 - val_accuracy: 0.8971 - val_loss: 0.6068\n",
      "Epoch 146/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9908 - loss: 0.0312 - val_accuracy: 0.9007 - val_loss: 0.5577\n",
      "Epoch 147/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0231 - val_accuracy: 0.8934 - val_loss: 0.5752\n",
      "Epoch 148/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9963 - loss: 0.0236 - val_accuracy: 0.8934 - val_loss: 0.6047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0269 - val_accuracy: 0.8750 - val_loss: 0.6129\n",
      "Epoch 150/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9890 - loss: 0.0385 - val_accuracy: 0.8860 - val_loss: 0.6414\n",
      "Epoch 151/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9926 - loss: 0.0299 - val_accuracy: 0.8897 - val_loss: 0.6028\n",
      "Epoch 152/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0208 - val_accuracy: 0.8787 - val_loss: 0.6238\n",
      "Epoch 153/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0233 - val_accuracy: 0.8824 - val_loss: 0.6347\n",
      "Epoch 154/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0224 - val_accuracy: 0.8934 - val_loss: 0.5779\n",
      "Epoch 155/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9963 - loss: 0.0224 - val_accuracy: 0.8750 - val_loss: 0.5989\n",
      "Epoch 156/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0198 - val_accuracy: 0.8860 - val_loss: 0.5492\n",
      "Epoch 157/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0188 - val_accuracy: 0.8897 - val_loss: 0.6289\n",
      "Epoch 158/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0183 - val_accuracy: 0.8750 - val_loss: 0.6651\n",
      "Epoch 159/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0219 - val_accuracy: 0.9007 - val_loss: 0.5776\n",
      "Epoch 160/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0183 - val_accuracy: 0.8860 - val_loss: 0.5980\n",
      "Epoch 161/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0167 - val_accuracy: 0.8897 - val_loss: 0.6527\n",
      "Epoch 162/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0177 - val_accuracy: 0.8860 - val_loss: 0.6172\n",
      "Epoch 163/200\n",
      "68/68 - 0s - 6ms/step - accuracy: 0.9963 - loss: 0.0203 - val_accuracy: 0.8824 - val_loss: 0.6477\n",
      "Epoch 164/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9954 - loss: 0.0200 - val_accuracy: 0.8897 - val_loss: 0.6276\n",
      "Epoch 165/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9982 - loss: 0.0178 - val_accuracy: 0.8787 - val_loss: 0.6528\n",
      "Epoch 166/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0194 - val_accuracy: 0.8860 - val_loss: 0.6738\n",
      "Epoch 167/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9963 - loss: 0.0200 - val_accuracy: 0.8897 - val_loss: 0.6529\n",
      "Epoch 168/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.9963 - loss: 0.0188 - val_accuracy: 0.8860 - val_loss: 0.6311\n",
      "Epoch 169/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0157 - val_accuracy: 0.8824 - val_loss: 0.6815\n",
      "Epoch 170/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0173 - val_accuracy: 0.8860 - val_loss: 0.6350\n",
      "Epoch 171/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0172 - val_accuracy: 0.8860 - val_loss: 0.5851\n",
      "Epoch 172/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0185 - val_accuracy: 0.8750 - val_loss: 0.6285\n",
      "Epoch 173/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0152 - val_accuracy: 0.8824 - val_loss: 0.7082\n",
      "Epoch 174/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0146 - val_accuracy: 0.8860 - val_loss: 0.6426\n",
      "Epoch 175/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0160 - val_accuracy: 0.8824 - val_loss: 0.6731\n",
      "Epoch 176/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0136 - val_accuracy: 0.8897 - val_loss: 0.6793\n",
      "Epoch 177/200\n",
      "68/68 - 0s - 2ms/step - accuracy: 0.9963 - loss: 0.0166 - val_accuracy: 0.8713 - val_loss: 0.6600\n",
      "Epoch 178/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0178 - val_accuracy: 0.8750 - val_loss: 0.6387\n",
      "Epoch 179/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9982 - loss: 0.0167 - val_accuracy: 0.8787 - val_loss: 0.7157\n",
      "Epoch 180/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0144 - val_accuracy: 0.8860 - val_loss: 0.6363\n",
      "Epoch 181/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0157 - val_accuracy: 0.8860 - val_loss: 0.6685\n",
      "Epoch 182/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 0.8824 - val_loss: 0.6964\n",
      "Epoch 183/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0108 - val_accuracy: 0.8824 - val_loss: 0.7270\n",
      "Epoch 184/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9991 - loss: 0.0117 - val_accuracy: 0.8824 - val_loss: 0.7107\n",
      "Epoch 185/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9945 - loss: 0.0149 - val_accuracy: 0.8971 - val_loss: 0.6652\n",
      "Epoch 186/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0143 - val_accuracy: 0.8824 - val_loss: 0.7177\n",
      "Epoch 187/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0100 - val_accuracy: 0.8787 - val_loss: 0.7021\n",
      "Epoch 188/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9991 - loss: 0.0102 - val_accuracy: 0.8860 - val_loss: 0.7182\n",
      "Epoch 189/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.8713 - val_loss: 0.7029\n",
      "Epoch 190/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0122 - val_accuracy: 0.8640 - val_loss: 0.7381\n",
      "Epoch 191/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0238 - val_accuracy: 0.8382 - val_loss: 0.9510\n",
      "Epoch 192/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9936 - loss: 0.0296 - val_accuracy: 0.8676 - val_loss: 0.8216\n",
      "Epoch 193/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0145 - val_accuracy: 0.8787 - val_loss: 0.7276\n",
      "Epoch 194/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0112 - val_accuracy: 0.8824 - val_loss: 0.7186\n",
      "Epoch 195/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0112 - val_accuracy: 0.8971 - val_loss: 0.7044\n",
      "Epoch 196/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 0.8787 - val_loss: 0.7149\n",
      "Epoch 197/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9972 - loss: 0.0110 - val_accuracy: 0.8897 - val_loss: 0.7711\n",
      "Epoch 198/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0107 - val_accuracy: 0.8787 - val_loss: 0.7641\n",
      "Epoch 199/200\n",
      "68/68 - 0s - 4ms/step - accuracy: 0.9972 - loss: 0.0142 - val_accuracy: 0.8897 - val_loss: 0.7435\n",
      "Epoch 200/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.9982 - loss: 0.0101 - val_accuracy: 0.8750 - val_loss: 0.7856\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = build_model(X_train1.shape[1])\n",
    "# trains the neural network\n",
    "# epochs = 200 -> Feeds training data through the model 200 times\n",
    "# give the model unseen data (validation data) to evaluate after each epoch\n",
    "# the model trains on mini-batches of 16 examples at a time\n",
    "history = model.fit(X_train1, y_train1, validation_data=(X_test1, y_test1), epochs=200, batch_size=16, verbose=2) # <- Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2ae76",
   "metadata": {},
   "source": [
    "###### Training with the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9fcb8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 - 2s - 23ms/step - accuracy: 0.5906 - loss: 0.8086 - val_accuracy: 0.8456 - val_loss: 0.5862 - learning_rate: 1.0000e-03\n",
      "Epoch 2/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.7360 - loss: 0.6272 - val_accuracy: 0.8676 - val_loss: 0.5073 - learning_rate: 1.0000e-03\n",
      "Epoch 3/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.7866 - loss: 0.5291 - val_accuracy: 0.8824 - val_loss: 0.4447 - learning_rate: 1.0000e-03\n",
      "Epoch 4/200\n",
      "68/68 - 0s - 5ms/step - accuracy: 0.8399 - loss: 0.4627 - val_accuracy: 0.8934 - val_loss: 0.3953 - learning_rate: 1.0000e-03\n",
      "Epoch 5/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8464 - loss: 0.4280 - val_accuracy: 0.8897 - val_loss: 0.3801 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8362 - loss: 0.4368 - val_accuracy: 0.8971 - val_loss: 0.3626 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8556 - loss: 0.4180 - val_accuracy: 0.8971 - val_loss: 0.3498 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "68/68 - 0s - 3ms/step - accuracy: 0.8703 - loss: 0.3775 - val_accuracy: 0.9007 - val_loss: 0.3433 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model1 = build_model1(X_train1.shape[1])\n",
    "# trains the neural network\n",
    "# epochs = 200 -> Feeds training data through the model 200 times\n",
    "# give the model unseen data (validation data) to evaluate after each epoch\n",
    "# the model trains on mini-batches of 16 examples at a time\n",
    "history1 = model1.fit(X_train1, y_train1, validation_data=(X_test1, y_test1), epochs=200, batch_size=16, verbose=2, callbacks=[es, rlr]) # <- Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b77446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Disk\n",
    "#json_file_path = \"/home/hduser/wine_model.json\"\n",
    "#h5_file_path = \"/home/hduser/wine_model.weights.h5\"\n",
    "\n",
    "#model_json = model1.to_json()\n",
    "#with open(json_file_path, \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "    \n",
    "#print(f\"Model architecture save to: {json_file_path}\")    \n",
    "\n",
    "#model.save_weights(h5_file_path)\n",
    "#print(f\"Model weights saved to: {h5_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e87eaa",
   "metadata": {},
   "source": [
    "###### Results for the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "709a9af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "[0.31546634 0.48363853 0.32154843 0.3077991  0.50754267 0.32467946\n",
      " 0.36066997 0.48754048 0.2523761  0.4111126  0.50571984 0.47470048\n",
      " 0.404102   0.4572613  0.349301   0.42418984 0.40078115 0.35422388\n",
      " 0.25409815 0.43357325 0.5174892  0.3665139  0.3312921  0.44488755\n",
      " 0.33526313 0.51698226 0.34314454 0.5357081  0.37184915 0.4565899\n",
      " 0.38029715 0.32754716 0.28073555 0.386036   0.5057764  0.3975875\n",
      " 0.41790414 0.32279184 0.3698294  0.4510662  0.41404182 0.3373943\n",
      " 0.54150796 0.3835834  0.33781686 0.40005243 0.5833386  0.37532374\n",
      " 0.586886   0.44416663 0.40071827 0.52255255 0.33502144 0.3780922\n",
      " 0.36502212 0.3893189  0.35417733 0.34855768 0.39475814 0.22891827\n",
      " 0.20553063 0.34740582 0.38316396 0.42502883 0.41662905 0.3369473\n",
      " 0.5049491  0.35864982 0.28458366 0.52423877 0.33570087 0.4804293\n",
      " 0.54377896 0.49471498 0.29459456 0.36386842 0.3975265  0.31536353\n",
      " 0.3961296  0.25583208 0.34269792 0.41935062 0.3566633  0.52371633\n",
      " 0.36599943 0.5742148  0.25198692 0.573983   0.39126247 0.2947785\n",
      " 0.32729274 0.51148623 0.47836655 0.4152299  0.37657574 0.50088406\n",
      " 0.4189094  0.33368367 0.28985867 0.28007048 0.3717329  0.32975954\n",
      " 0.47979596 0.37139934 0.3818693  0.2513916  0.32448822 0.32931545\n",
      " 0.47360528 0.2923806  0.50563335 0.50629777 0.20789205 0.30851102\n",
      " 0.38165575 0.3972111  0.36678937 0.3526568  0.59180015 0.50811386\n",
      " 0.52502054 0.5900202  0.3677668  0.37681174 0.4177976  0.41619095\n",
      " 0.3124598  0.39477974 0.4030693  0.33932626 0.34479362 0.33848393\n",
      " 0.3769073  0.5346974  0.5860261  0.29027826 0.3225579  0.52615887\n",
      " 0.29489002 0.3316693  0.45105112 0.3305556  0.53613275 0.5219159\n",
      " 0.48138073 0.5081723  0.34921324 0.3953432  0.42595157 0.4199087\n",
      " 0.4510584  0.3029816  0.484389   0.36023843 0.41858515 0.39786172\n",
      " 0.43619812 0.34151384 0.5417     0.43503395 0.36603105 0.36258042\n",
      " 0.4512345  0.38744986 0.31011662 0.47764838 0.43070337 0.27242753\n",
      " 0.3657339  0.4118957  0.38908178 0.3700178  0.29872778 0.62422806\n",
      " 0.390954   0.34059465 0.4382912  0.5284915  0.4939829  0.3549697\n",
      " 0.3242449  0.3861058  0.37074155 0.57823753 0.49021378 0.36444455\n",
      " 0.37819037 0.48092544 0.34599727 0.398848   0.49020484 0.3198118\n",
      " 0.3418752  0.32722956 0.20624237 0.35341153 0.4328169  0.36424726\n",
      " 0.5943416  0.46745127 0.46483612 0.31357333 0.22206098 0.32550612\n",
      " 0.47586727 0.2579529  0.27486497 0.43426016 0.39958867 0.25499427\n",
      " 0.32524732 0.3272835  0.3826108  0.36704028 0.32099852 0.43339676\n",
      " 0.46981424 0.36662394 0.3095663  0.43254972 0.37312976 0.4643388\n",
      " 0.2949895  0.41101825 0.3869252  0.55974656 0.43267274 0.38178042\n",
      " 0.28808448 0.50025046 0.38227838 0.4874242  0.6221908  0.49361667\n",
      " 0.3073464  0.5009712  0.47829175 0.4693574  0.21058218 0.36274123\n",
      " 0.33486536 0.5028284  0.29773292 0.3477312  0.39310417 0.37754598\n",
      " 0.5434275  0.5190049  0.34599695 0.3633746  0.3846566  0.30989724\n",
      " 0.3614878  0.2793546  0.37915573 0.32319167 0.4517304  0.36858052\n",
      " 0.22504923 0.48907343 0.27998853 0.55755043 0.35829023 0.4978066\n",
      " 0.45608    0.48700297 0.54266083 0.3742757  0.3316309  0.37298715\n",
      " 0.3852539  0.27119586]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on unseen data (X_test1)\n",
    "# and then print the probabilities\n",
    "predictions = model1.predict(X_test1).ravel()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb9882dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 1 0 1 1 0 0 0 0 0]\n",
      "Pred type:  <class 'numpy.ndarray'>\n",
      "Shape of pred:  272\n",
      "Dataset type:  <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.46  # I can try with different threshold 0.3, 0.4, 0.5, etc.\n",
    "pred = (predictions >= threshold).astype(int)\n",
    "print(pred)\n",
    "\n",
    "print(\"Pred type: \", type(pred)) \n",
    "print(\"Shape of pred: \", len(pred))\n",
    "print(\"Dataset type: \", type(clean_old_df)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4708c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f36d049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot how the model learned over time (epoch by epoch).\n",
    "# Keras returns a History object that stores the training progress\n",
    "# history.history is a dictionary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history1.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history1.history[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43de1d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.945     0.812     0.874       234\n",
      "           1      0.380     0.711     0.495        38\n",
      "\n",
      "    accuracy                          0.798       272\n",
      "   macro avg      0.663     0.761     0.684       272\n",
      "weighted avg      0.866     0.798     0.821       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Confusion_matrix -> build the table comparing true vs predicted labels\n",
    "\n",
    "cm = confusion_matrix(y_test1, pred)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "# Classification_report -> compute precision, recall, and F1-score.\n",
    "print(classification_report(y_test1, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc228893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: /home/hduser/venvs/spark-delta/bin/python\n",
      "PySpark ver: 3.5.1\n",
      "Delta Lake (delta-spark) version: 3.2.0\n",
      "Spark: 3.5.6\n",
      "JARs: Vector(spark://BDSP:35965/jars/delta-storage-3.2.0.jar, spark://BDSP:35965/jars/delta-spark_2.12-3.2.0.jar)\n"
     ]
    }
   ],
   "source": [
    "import sys, pyspark\n",
    "import importlib.metadata\n",
    "\n",
    "print(\"Python exe:\", sys.executable)  # expect ~/venvs/spark-delta/bin/python\n",
    "print(\"PySpark ver:\", pyspark.__version__)\n",
    "print(\"Delta Lake (delta-spark) version:\", importlib.metadata.version(\"delta-spark\"))\n",
    "\n",
    "print(\"Spark:\", spark.version)\n",
    "print(\"JARs:\", spark._jsc.sc().listJars().toString())  # expect delta-spark + delta-storage listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78627f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
